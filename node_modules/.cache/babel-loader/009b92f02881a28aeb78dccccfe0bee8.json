{"ast":null,"code":"var _jsxFileName = \"/Users/a2017/Documents/GitHub/js-faceai/src/App.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect } from 'react';\nimport \"./App.css\";\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function App() {\n  _s();\n\n  useEffect(() => {\n    Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri(\"./models\"), faceapi.nets.faceLandmark68Net.loadFromUri(\"./models\"), faceapi.nets.faceRecognitionNet.loadFromUri(\"./models\"), faceapi.nets.faceExpressionNet.loadFromUri(\"./models\")]).then(startCamera());\n    const video = document.getElementById(\"video\");\n\n    function startCamera() {\n      navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;\n      navigator.getUserMedia({\n        audio: false,\n        video: {\n          width: 1280,\n          height: 720\n        }\n      }, stream => video.srcObject = stream, err => console.log(err));\n    }\n\n    video.play();\n    video.addEventListener(\"play\", () => {\n      setInterval(async () => {\n        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n        console.log(detections);\n      }, 100);\n    });\n  });\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"main\",\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      id: \"video\",\n      width: \"1280\",\n      height: \"720\",\n      autoplay: true,\n      muted: true\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 43,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 42,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"OD7bBpZva5O2jO+Puf00hKivP7c=\");\n\n_c = App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/a2017/Documents/GitHub/js-faceai/src/App.js"],"names":["React","useEffect","faceapi","App","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","startCamera","video","document","getElementById","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","audio","width","height","stream","srcObject","err","console","log","play","addEventListener","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAO,WAAP;AAEA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;;AAEA,eAAe,SAASC,GAAT,GAAe;AAAA;;AAE5BF,EAAAA,SAAS,CAAC,MAAM;AAEdG,IAAAA,OAAO,CAACC,GAAR,CAAY,CACVH,OAAO,CAACI,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0C,UAA1C,CADU,EAEVN,OAAO,CAACI,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2C,UAA3C,CAFU,EAGVN,OAAO,CAACI,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4C,UAA5C,CAHU,EAIVN,OAAO,CAACI,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2C,UAA3C,CAJU,CAAZ,EAKGI,IALH,CAKQC,WAAW,EALnB;AAQA,UAAMC,KAAK,GAAGC,QAAQ,CAACC,cAAT,CAAwB,OAAxB,CAAd;;AAEA,aAASH,WAAT,GAAuB;AACrBI,MAAAA,SAAS,CAACC,YAAV,GAAyBD,SAAS,CAACC,YAAV,IACvBD,SAAS,CAACE,kBADa,IAEvBF,SAAS,CAACG,eAFZ;AAIAH,MAAAA,SAAS,CAACC,YAAV,CAAuB;AACrBG,QAAAA,KAAK,EAAE,KADc;AACPP,QAAAA,KAAK,EAAE;AAAEQ,UAAAA,KAAK,EAAE,IAAT;AAAeC,UAAAA,MAAM,EAAE;AAAvB;AADA,OAAvB,EAEGC,MAAM,IAAKV,KAAK,CAACW,SAAN,GAAkBD,MAFhC,EAGEE,GAAG,IAAIC,OAAO,CAACC,GAAR,CAAYF,GAAZ,CAHT;AAID;;AACDZ,IAAAA,KAAK,CAACe,IAAN;AAEAf,IAAAA,KAAK,CAACgB,gBAAN,CAAuB,MAAvB,EAA+B,MAAM;AACnCC,MAAAA,WAAW,CAAC,YAAY;AACtB,cAAMC,UAAU,GAAG,MAAM9B,OAAO,CAAC+B,cAAR,CAAuBnB,KAAvB,EAA8B,IAAIZ,OAAO,CAACgC,uBAAZ,EAA9B,CAAzB;AAEAP,QAAAA,OAAO,CAACC,GAAR,CAAYI,UAAZ;AACD,OAJU,EAIR,GAJQ,CAAX;AAKD,KAND;AAOD,GA/BQ,CAAT;AAiCA,sBACE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA,2BACE;AAAO,MAAA,EAAE,EAAC,OAAV;AAAkB,MAAA,KAAK,EAAC,MAAxB;AAA+B,MAAA,MAAM,EAAC,KAAtC;AAA4C,MAAA,QAAQ,MAApD;AAAqD,MAAA,KAAK;AAA1D;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,UADF;AAKD;;GAxCuB7B,G;;KAAAA,G","sourcesContent":["import React, { useEffect } from 'react';\nimport \"./App.css\";\n\nimport * as faceapi from 'face-api.js';\n\nexport default function App() {\n\n  useEffect(() => {\n\n    Promise.all([\n      faceapi.nets.tinyFaceDetector.loadFromUri(\"./models\"),\n      faceapi.nets.faceLandmark68Net.loadFromUri(\"./models\"),\n      faceapi.nets.faceRecognitionNet.loadFromUri(\"./models\"),\n      faceapi.nets.faceExpressionNet.loadFromUri(\"./models\")\n    ]).then(startCamera());\n\n\n    const video = document.getElementById(\"video\");\n\n    function startCamera() {\n      navigator.getUserMedia = navigator.getUserMedia ||\n        navigator.webkitGetUserMedia ||\n        navigator.mozGetUserMedia;\n\n      navigator.getUserMedia({\n        audio: false, video: { width: 1280, height: 720 }\n      }, stream => (video.srcObject = stream),\n        err => console.log(err))\n    }\n    video.play();\n\n    video.addEventListener(\"play\", () => {\n      setInterval(async () => {\n        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());\n\n        console.log(detections)\n      }, 100)\n    })\n  });\n\n  return (\n    <div className=\"main\">\n      <video id=\"video\" width=\"1280\" height=\"720\" autoplay muted ></video>\n    </div>\n  )\n}\n\n"]},"metadata":{},"sourceType":"module"}