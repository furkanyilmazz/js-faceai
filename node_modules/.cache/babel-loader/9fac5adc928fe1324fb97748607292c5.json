{"ast":null,"code":"var _jsxFileName = \"/Users/a2017/Documents/GitHub/js-faceai/src/App.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState, useRef } from 'react';\nimport \"./App.css\";\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function App() {\n  _s();\n\n  const videoHeight = 720;\n  const videoWidth = 1280;\n  const [initializing, setInitializing] = useState(false);\n  const videoRef = useRef();\n  const canvasRef = useRef();\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      setInitializing(true);\n      Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL), faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL), faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL), faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)]).then(startVideo);\n    };\n\n    loadModels();\n  }, []);\n\n  const startVideo = () => {\n    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;\n\n    if (navigator.getUserMedia) {\n      navigator.getUserMedia({\n        audio: false,\n        video: {\n          width: 1280,\n          height: 720\n        }\n      }, function (stream) {\n        var video = document.querySelector('video');\n        video.srcObject = stream;\n\n        video.onloadedmetadata = function (e) {\n          video.play();\n        };\n      }, function (err) {\n        console.log(\"The following error occurred: \" + err.name);\n      });\n    } else {\n      console.log(\"getUserMedia not supported\");\n    }\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (initializing) {\n        setInitializing(false);\n      }\n\n      canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(videoRef.current);\n      const displaySize = {\n        width: videoWidth,\n        heigth: videoHeight\n      };\n      faceapi.matchDimensions(canvasRef.current, displaySize);\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      const resizedDetections = faceapi.resizeResults(detections, displaySize);\n      canvasRef.current.getContext(\"2d\").clearRect(0, 0, videoWidth, videoHeight);\n      faceapi.draw.drawDetections(canvasRef.current, detections);\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, detections);\n      faceapi.draw.drawFaceExpressions(canvasRef.current, detections);\n      console.log(detections);\n    }, 100);\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"main\",\n    children: [/*#__PURE__*/_jsxDEV(\"span\", {\n      children: initializing ? \"Initializing\" : \"Ready\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 76,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"video\", {\n        id: \"video\",\n        className: \"video\",\n        ref: videoRef,\n        autoplay: true,\n        muted: true,\n        height: videoHeight,\n        width: videoWidth,\n        onPlay: handleVideoOnPlay\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 78,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 79,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 77,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 75,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"Xg6yX5IqQ2Gk/jClXeKvvsq5YQk=\");\n\n_c = App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/a2017/Documents/GitHub/js-faceai/src/App.js"],"names":["React","useEffect","useState","useRef","faceapi","App","videoHeight","videoWidth","initializing","setInitializing","videoRef","canvasRef","loadModels","MODEL_URL","process","env","PUBLIC_URL","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","startVideo","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","audio","video","width","height","stream","document","querySelector","srcObject","onloadedmetadata","e","play","err","console","log","name","handleVideoOnPlay","setInterval","current","innerHTML","createCanvasFromMedia","displaySize","heigth","matchDimensions","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","resizedDetections","resizeResults","getContext","clearRect","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,QAA3B,EAAqCC,MAArC,QAAmD,OAAnD;AACA,OAAO,WAAP;AAEA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;;AAEA,eAAe,SAASC,GAAT,GAAe;AAAA;;AAE5B,QAAMC,WAAW,GAAG,GAApB;AACA,QAAMC,UAAU,GAAG,IAAnB;AACA,QAAM,CAACC,YAAD,EAAeC,eAAf,IAAkCP,QAAQ,CAAC,KAAD,CAAhD;AACA,QAAMQ,QAAQ,GAAGP,MAAM,EAAvB;AACA,QAAMQ,SAAS,GAAGR,MAAM,EAAxB;AAEAF,EAAAA,SAAS,CAAC,MAAM;AACd,UAAMW,UAAU,GAAG,YAAY;AAC7B,YAAMC,SAAS,GAAGC,OAAO,CAACC,GAAR,CAAYC,UAAZ,GAAyB,SAA3C;AACAP,MAAAA,eAAe,CAAC,IAAD,CAAf;AACAQ,MAAAA,OAAO,CAACC,GAAR,CAAY,CACVd,OAAO,CAACe,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0CR,SAA1C,CADU,EAEVT,OAAO,CAACe,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2CR,SAA3C,CAFU,EAGVT,OAAO,CAACe,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4CR,SAA5C,CAHU,EAIVT,OAAO,CAACe,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2CR,SAA3C,CAJU,CAAZ,EAKGY,IALH,CAKQC,UALR;AAMD,KATD;;AAUAd,IAAAA,UAAU;AACX,GAZQ,EAYN,EAZM,CAAT;;AAcA,QAAMc,UAAU,GAAG,MAAM;AACvBC,IAAAA,SAAS,CAACC,YAAV,GAAyBD,SAAS,CAACC,YAAV,IACvBD,SAAS,CAACE,kBADa,IAEvBF,SAAS,CAACG,eAFZ;;AAIA,QAAIH,SAAS,CAACC,YAAd,EAA4B;AAC1BD,MAAAA,SAAS,CAACC,YAAV,CAAuB;AAAEG,QAAAA,KAAK,EAAE,KAAT;AAAgBC,QAAAA,KAAK,EAAE;AAAEC,UAAAA,KAAK,EAAE,IAAT;AAAeC,UAAAA,MAAM,EAAE;AAAvB;AAAvB,OAAvB,EACE,UAAUC,MAAV,EAAkB;AAChB,YAAIH,KAAK,GAAGI,QAAQ,CAACC,aAAT,CAAuB,OAAvB,CAAZ;AACAL,QAAAA,KAAK,CAACM,SAAN,GAAkBH,MAAlB;;AACAH,QAAAA,KAAK,CAACO,gBAAN,GAAyB,UAAUC,CAAV,EAAa;AACpCR,UAAAA,KAAK,CAACS,IAAN;AACD,SAFD;AAGD,OAPH,EAQE,UAAUC,GAAV,EAAe;AACbC,QAAAA,OAAO,CAACC,GAAR,CAAY,mCAAmCF,GAAG,CAACG,IAAnD;AACD,OAVH;AAYD,KAbD,MAaO;AACLF,MAAAA,OAAO,CAACC,GAAR,CAAY,4BAAZ;AACD;AAGF,GAvBD;;AAyBA,QAAME,iBAAiB,GAAG,MAAM;AAC9BC,IAAAA,WAAW,CAAC,YAAY;AACtB,UAAIvC,YAAJ,EAAkB;AAChBC,QAAAA,eAAe,CAAC,KAAD,CAAf;AACD;;AACDE,MAAAA,SAAS,CAACqC,OAAV,CAAkBC,SAAlB,GAA8B7C,OAAO,CAAC8C,qBAAR,CAA8BxC,QAAQ,CAACsC,OAAvC,CAA9B;AACA,YAAMG,WAAW,GAAG;AAClBlB,QAAAA,KAAK,EAAE1B,UADW;AAElB6C,QAAAA,MAAM,EAAE9C;AAFU,OAApB;AAIAF,MAAAA,OAAO,CAACiD,eAAR,CAAwB1C,SAAS,CAACqC,OAAlC,EAA2CG,WAA3C;AACA,YAAMG,UAAU,GAAG,MAAMlD,OAAO,CAACmD,cAAR,CAAuB7C,QAAQ,CAACsC,OAAhC,EAAyC,IAAI5C,OAAO,CAACoD,uBAAZ,EAAzC,EAAgFC,iBAAhF,GAAoGC,mBAApG,EAAzB;AACA,YAAMC,iBAAiB,GAAGvD,OAAO,CAACwD,aAAR,CAAsBN,UAAtB,EAAkCH,WAAlC,CAA1B;AACAxC,MAAAA,SAAS,CAACqC,OAAV,CAAkBa,UAAlB,CAA6B,IAA7B,EAAmCC,SAAnC,CAA6C,CAA7C,EAAgD,CAAhD,EAAmDvD,UAAnD,EAA+DD,WAA/D;AACAF,MAAAA,OAAO,CAAC2D,IAAR,CAAaC,cAAb,CAA4BrD,SAAS,CAACqC,OAAtC,EAA+CM,UAA/C;AACAlD,MAAAA,OAAO,CAAC2D,IAAR,CAAaE,iBAAb,CAA+BtD,SAAS,CAACqC,OAAzC,EAAkDM,UAAlD;AACAlD,MAAAA,OAAO,CAAC2D,IAAR,CAAaG,mBAAb,CAAiCvD,SAAS,CAACqC,OAA3C,EAAoDM,UAApD;AACAX,MAAAA,OAAO,CAACC,GAAR,CAAYU,UAAZ;AACD,KAjBU,EAiBR,GAjBQ,CAAX;AAkBD,GAnBD;;AAqBA,sBACE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA,4BACE;AAAA,gBAAO9C,YAAY,GAAG,cAAH,GAAoB;AAAvC;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAA,8BACE;AAAO,QAAA,EAAE,EAAC,OAAV;AAAkB,QAAA,SAAS,EAAC,OAA5B;AAAoC,QAAA,GAAG,EAAEE,QAAzC;AAAmD,QAAA,QAAQ,MAA3D;AAA4D,QAAA,KAAK,MAAjE;AAAkE,QAAA,MAAM,EAAEJ,WAA1E;AAAuF,QAAA,KAAK,EAAEC,UAA9F;AAA0G,QAAA,MAAM,EAAEuC;AAAlH;AAAA;AAAA;AAAA;AAAA,cADF,eAEE;AAAQ,QAAA,GAAG,EAAEnC;AAAb;AAAA;AAAA;AAAA;AAAA,cAFF;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AASD;;GA7EuBN,G;;KAAAA,G","sourcesContent":["import React, { useEffect, useState, useRef } from 'react';\nimport \"./App.css\";\n\nimport * as faceapi from 'face-api.js';\n\nexport default function App() {\n\n  const videoHeight = 720;\n  const videoWidth = 1280;\n  const [initializing, setInitializing] = useState(false)\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      setInitializing(true);\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)\n      ]).then(startVideo)\n    }\n    loadModels();\n  }, []);\n\n  const startVideo = () => {\n    navigator.getUserMedia = navigator.getUserMedia ||\n      navigator.webkitGetUserMedia ||\n      navigator.mozGetUserMedia;\n\n    if (navigator.getUserMedia) {\n      navigator.getUserMedia({ audio: false, video: { width: 1280, height: 720 }, },\n        function (stream) {\n          var video = document.querySelector('video');\n          video.srcObject = stream;\n          video.onloadedmetadata = function (e) {\n            video.play();\n          };\n        },\n        function (err) {\n          console.log(\"The following error occurred: \" + err.name);\n        }\n      );\n    } else {\n      console.log(\"getUserMedia not supported\");\n    }\n\n\n  }\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (initializing) {\n        setInitializing(false);\n      }\n      canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(videoRef.current);\n      const displaySize = {\n        width: videoWidth,\n        heigth: videoHeight\n      }\n      faceapi.matchDimensions(canvasRef.current, displaySize);\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      const resizedDetections = faceapi.resizeResults(detections, displaySize);\n      canvasRef.current.getContext(\"2d\").clearRect(0, 0, videoWidth, videoHeight);\n      faceapi.draw.drawDetections(canvasRef.current, detections);\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, detections);\n      faceapi.draw.drawFaceExpressions(canvasRef.current, detections)\n      console.log(detections);\n    }, 100)\n  }\n\n  return (\n    <div className=\"main\">\n      <span>{initializing ? \"Initializing\" : \"Ready\"}</span>\n      <div>\n        <video id=\"video\" className=\"video\" ref={videoRef} autoplay muted height={videoHeight} width={videoWidth} onPlay={handleVideoOnPlay} />\n        <canvas ref={canvasRef} />\n      </div>\n    </div>\n  )\n}\n\n"]},"metadata":{},"sourceType":"module"}