{"ast":null,"code":"import _regeneratorRuntime from\"/Users/a2017/Documents/GitHub/js-faceai/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";import _asyncToGenerator from\"/Users/a2017/Documents/GitHub/js-faceai/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";import _slicedToArray from\"/Users/a2017/Documents/GitHub/js-faceai/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";import React,{useEffect,useState,useRef}from'react';import\"./App.css\";import*as faceapi from'face-api.js';import{jsx as _jsx}from\"react/jsx-runtime\";import{jsxs as _jsxs}from\"react/jsx-runtime\";export default function App(){var videoHeight=720;var videoWidth=1280;var _useState=useState(false),_useState2=_slicedToArray(_useState,2),initializing=_useState2[0],setInitializing=_useState2[1];var videoRef=useRef();var canvasRef=useRef();useEffect(function(){var loadModels=/*#__PURE__*/function(){var _ref=_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime.mark(function _callee(){var MODEL_URL;return _regeneratorRuntime.wrap(function _callee$(_context){while(1){switch(_context.prev=_context.next){case 0:MODEL_URL=process.env.PUBLIC_URL+'/models';setInitializing(true);Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)]).then(startVideo);case 3:case\"end\":return _context.stop();}}},_callee);}));return function loadModels(){return _ref.apply(this,arguments);};}();loadModels();},[]);var startVideo=function startVideo(){navigator.getUserMedia=navigator.getUserMedia||navigator.webkitGetUserMedia||navigator.mozGetUserMedia;if(navigator.getUserMedia){navigator.getUserMedia({audio:false,video:{width:1280,height:720}},function(stream){var video=document.querySelector('video');video.srcObject=stream;video.onloadedmetadata=function(e){video.play();};},function(err){console.log(\"The following error occurred: \"+err.name);});}else{console.log(\"getUserMedia not supported\");}};var handleVideoOnPlay=function handleVideoOnPlay(){setInterval(/*#__PURE__*/_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime.mark(function _callee2(){var displaySize,detections,resizedDetections;return _regeneratorRuntime.wrap(function _callee2$(_context2){while(1){switch(_context2.prev=_context2.next){case 0:if(initializing){setInitializing(false);}canvasRef.current.innerHTML=faceapi.createCanvasFromMedia(videoRef.current);displaySize={width:videoWidth,heigth:videoHeight};faceapi.matchDimensions(canvasRef.current,displaySize);_context2.next=6;return faceapi.detectAllFaces(videoRef.current,new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();case 6:detections=_context2.sent;resizedDetections=faceapi.resizeResults(detections,displaySize);canvasRef.current.getContext(\"2d\").clearRect(0,0,videoWidth,videoHeight);faceapi.draw.drawDetections(canvasRef.current,resizedDetections);faceapi.draw.drawFaceLandmarks(canvasRef.current,resizedDetections);faceapi.draw.drawFaceExpressions(canvasRef.current,resizedDetections);console.log(detections);case 13:case\"end\":return _context2.stop();}}},_callee2);})),100);};return/*#__PURE__*/_jsxs(\"div\",{className:\"main\",children:[/*#__PURE__*/_jsx(\"span\",{children:initializing?\"Initializing\":\"Ready\"}),/*#__PURE__*/_jsxs(\"div\",{children:[/*#__PURE__*/_jsx(\"video\",{id:\"video\",className:\"video\",ref:videoRef,autoplay:true,muted:true,height:videoHeight,width:videoWidth,onPlay:handleVideoOnPlay}),/*#__PURE__*/_jsx(\"canvas\",{ref:canvasRef})]})]});}","map":{"version":3,"sources":["/Users/a2017/Documents/GitHub/js-faceai/src/App.js"],"names":["React","useEffect","useState","useRef","faceapi","App","videoHeight","videoWidth","initializing","setInitializing","videoRef","canvasRef","loadModels","MODEL_URL","process","env","PUBLIC_URL","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","startVideo","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","audio","video","width","height","stream","document","querySelector","srcObject","onloadedmetadata","e","play","err","console","log","name","handleVideoOnPlay","setInterval","current","innerHTML","createCanvasFromMedia","displaySize","heigth","matchDimensions","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","detections","resizedDetections","resizeResults","getContext","clearRect","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions"],"mappings":"udAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,CAA2BC,QAA3B,CAAqCC,MAArC,KAAmD,OAAnD,CACA,MAAO,WAAP,CAEA,MAAO,GAAKC,CAAAA,OAAZ,KAAyB,aAAzB,C,wFAEA,cAAe,SAASC,CAAAA,GAAT,EAAe,CAE5B,GAAMC,CAAAA,WAAW,CAAG,GAApB,CACA,GAAMC,CAAAA,UAAU,CAAG,IAAnB,CAH4B,cAIYL,QAAQ,CAAC,KAAD,CAJpB,wCAIrBM,YAJqB,eAIPC,eAJO,eAK5B,GAAMC,CAAAA,QAAQ,CAAGP,MAAM,EAAvB,CACA,GAAMQ,CAAAA,SAAS,CAAGR,MAAM,EAAxB,CAEAF,SAAS,CAAC,UAAM,CACd,GAAMW,CAAAA,UAAU,0FAAG,iJACXC,SADW,CACCC,OAAO,CAACC,GAAR,CAAYC,UAAZ,CAAyB,SAD1B,CAEjBP,eAAe,CAAC,IAAD,CAAf,CACAQ,OAAO,CAACC,GAAR,CAAY,CACVd,OAAO,CAACe,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0CR,SAA1C,CADU,CAEVT,OAAO,CAACe,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2CR,SAA3C,CAFU,CAGVT,OAAO,CAACe,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4CR,SAA5C,CAHU,CAIVT,OAAO,CAACe,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2CR,SAA3C,CAJU,CAAZ,EAKGY,IALH,CAKQC,UALR,EAHiB,sDAAH,kBAAVd,CAAAA,UAAU,0CAAhB,CAUAA,UAAU,GACX,CAZQ,CAYN,EAZM,CAAT,CAcA,GAAMc,CAAAA,UAAU,CAAG,QAAbA,CAAAA,UAAa,EAAM,CACvBC,SAAS,CAACC,YAAV,CAAyBD,SAAS,CAACC,YAAV,EACvBD,SAAS,CAACE,kBADa,EAEvBF,SAAS,CAACG,eAFZ,CAIA,GAAIH,SAAS,CAACC,YAAd,CAA4B,CAC1BD,SAAS,CAACC,YAAV,CAAuB,CAAEG,KAAK,CAAE,KAAT,CAAgBC,KAAK,CAAE,CAAEC,KAAK,CAAE,IAAT,CAAeC,MAAM,CAAE,GAAvB,CAAvB,CAAvB,CACE,SAAUC,MAAV,CAAkB,CAChB,GAAIH,CAAAA,KAAK,CAAGI,QAAQ,CAACC,aAAT,CAAuB,OAAvB,CAAZ,CACAL,KAAK,CAACM,SAAN,CAAkBH,MAAlB,CACAH,KAAK,CAACO,gBAAN,CAAyB,SAAUC,CAAV,CAAa,CACpCR,KAAK,CAACS,IAAN,GACD,CAFD,CAGD,CAPH,CAQE,SAAUC,GAAV,CAAe,CACbC,OAAO,CAACC,GAAR,CAAY,iCAAmCF,GAAG,CAACG,IAAnD,EACD,CAVH,EAYD,CAbD,IAaO,CACLF,OAAO,CAACC,GAAR,CAAY,4BAAZ,EACD,CAGF,CAvBD,CAyBA,GAAME,CAAAA,iBAAiB,CAAG,QAApBA,CAAAA,iBAAoB,EAAM,CAC9BC,WAAW,sEAAC,qLACV,GAAIvC,YAAJ,CAAkB,CAChBC,eAAe,CAAC,KAAD,CAAf,CACD,CACDE,SAAS,CAACqC,OAAV,CAAkBC,SAAlB,CAA8B7C,OAAO,CAAC8C,qBAAR,CAA8BxC,QAAQ,CAACsC,OAAvC,CAA9B,CACMG,WALI,CAKU,CAClBlB,KAAK,CAAE1B,UADW,CAElB6C,MAAM,CAAE9C,WAFU,CALV,CASVF,OAAO,CAACiD,eAAR,CAAwB1C,SAAS,CAACqC,OAAlC,CAA2CG,WAA3C,EATU,uBAUe/C,CAAAA,OAAO,CAACkD,cAAR,CAAuB5C,QAAQ,CAACsC,OAAhC,CAAyC,GAAI5C,CAAAA,OAAO,CAACmD,uBAAZ,EAAzC,EAAgFC,iBAAhF,GAAoGC,mBAApG,EAVf,QAUJC,UAVI,gBAWJC,iBAXI,CAWgBvD,OAAO,CAACwD,aAAR,CAAsBF,UAAtB,CAAkCP,WAAlC,CAXhB,CAYVxC,SAAS,CAACqC,OAAV,CAAkBa,UAAlB,CAA6B,IAA7B,EAAmCC,SAAnC,CAA6C,CAA7C,CAAgD,CAAhD,CAAmDvD,UAAnD,CAA+DD,WAA/D,EACAF,OAAO,CAAC2D,IAAR,CAAaC,cAAb,CAA4BrD,SAAS,CAACqC,OAAtC,CAA+CW,iBAA/C,EACAvD,OAAO,CAAC2D,IAAR,CAAaE,iBAAb,CAA+BtD,SAAS,CAACqC,OAAzC,CAAkDW,iBAAlD,EACAvD,OAAO,CAAC2D,IAAR,CAAaG,mBAAb,CAAiCvD,SAAS,CAACqC,OAA3C,CAAoDW,iBAApD,EACAhB,OAAO,CAACC,GAAR,CAAYc,UAAZ,EAhBU,yDAAD,GAiBR,GAjBQ,CAAX,CAkBD,CAnBD,CAqBA,mBACE,aAAK,SAAS,CAAC,MAAf,wBACE,sBAAOlD,YAAY,CAAG,cAAH,CAAoB,OAAvC,EADF,cAEE,oCACE,cAAO,EAAE,CAAC,OAAV,CAAkB,SAAS,CAAC,OAA5B,CAAoC,GAAG,CAAEE,QAAzC,CAAmD,QAAQ,KAA3D,CAA4D,KAAK,KAAjE,CAAkE,MAAM,CAAEJ,WAA1E,CAAuF,KAAK,CAAEC,UAA9F,CAA0G,MAAM,CAAEuC,iBAAlH,EADF,cAEE,eAAQ,GAAG,CAAEnC,SAAb,EAFF,GAFF,GADF,CASD","sourcesContent":["import React, { useEffect, useState, useRef } from 'react';\nimport \"./App.css\";\n\nimport * as faceapi from 'face-api.js';\n\nexport default function App() {\n\n  const videoHeight = 720;\n  const videoWidth = 1280;\n  const [initializing, setInitializing] = useState(false)\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      setInitializing(true);\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)\n      ]).then(startVideo)\n    }\n    loadModels();\n  }, []);\n\n  const startVideo = () => {\n    navigator.getUserMedia = navigator.getUserMedia ||\n      navigator.webkitGetUserMedia ||\n      navigator.mozGetUserMedia;\n\n    if (navigator.getUserMedia) {\n      navigator.getUserMedia({ audio: false, video: { width: 1280, height: 720 }, },\n        function (stream) {\n          var video = document.querySelector('video');\n          video.srcObject = stream;\n          video.onloadedmetadata = function (e) {\n            video.play();\n          };\n        },\n        function (err) {\n          console.log(\"The following error occurred: \" + err.name);\n        }\n      );\n    } else {\n      console.log(\"getUserMedia not supported\");\n    }\n\n\n  }\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (initializing) {\n        setInitializing(false);\n      }\n      canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(videoRef.current);\n      const displaySize = {\n        width: videoWidth,\n        heigth: videoHeight\n      }\n      faceapi.matchDimensions(canvasRef.current, displaySize);\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      const resizedDetections = faceapi.resizeResults(detections, displaySize);\n      canvasRef.current.getContext(\"2d\").clearRect(0, 0, videoWidth, videoHeight);\n      faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n      console.log(detections);\n    }, 100)\n  }\n\n  return (\n    <div className=\"main\">\n      <span>{initializing ? \"Initializing\" : \"Ready\"}</span>\n      <div>\n        <video id=\"video\" className=\"video\" ref={videoRef} autoplay muted height={videoHeight} width={videoWidth} onPlay={handleVideoOnPlay} />\n        <canvas ref={canvasRef} />\n      </div>\n    </div>\n  )\n}\n\n"]},"metadata":{},"sourceType":"module"}