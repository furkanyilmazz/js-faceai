{"ast":null,"code":"var _jsxFileName = \"/Users/a2017/Documents/GitHub/js-faceai/src/App.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState, useRef } from 'react';\nimport \"./App.css\";\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function App() {\n  _s();\n\n  const videoHeight = 720;\n  const videoWidth = 1280;\n  const [initializing, setInitializing] = useState(false);\n  const videoRef = useRef();\n  const canvasRef = useRef();\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      setInitializing(true);\n      Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL), faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL), faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL), faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)]);\n    };\n  });\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"main\",\n    children: [/*#__PURE__*/_jsxDEV(\"span\", {\n      children: initializing ? \"Initializing\" : \"Ready\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 29,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      id: \"video\",\n      autoplay: true,\n      muted: true,\n      height: videoHeight,\n      width: videoWidth\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 31,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 28,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"Xg6yX5IqQ2Gk/jClXeKvvsq5YQk=\");\n\n_c = App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/a2017/Documents/GitHub/js-faceai/src/App.js"],"names":["React","useEffect","useState","useRef","faceapi","App","videoHeight","videoWidth","initializing","setInitializing","videoRef","canvasRef","loadModels","MODEL_URL","process","env","PUBLIC_URL","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,QAA3B,EAAqCC,MAArC,QAAmD,OAAnD;AACA,OAAO,WAAP;AAEA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;;AAEA,eAAe,SAASC,GAAT,GAAe;AAAA;;AAE5B,QAAMC,WAAW,GAAG,GAApB;AACA,QAAMC,UAAU,GAAG,IAAnB;AACA,QAAM,CAACC,YAAD,EAAeC,eAAf,IAAkCP,QAAQ,CAAC,KAAD,CAAhD;AACA,QAAMQ,QAAQ,GAAGP,MAAM,EAAvB;AACA,QAAMQ,SAAS,GAAGR,MAAM,EAAxB;AAEAF,EAAAA,SAAS,CAAC,MAAM;AACd,UAAMW,UAAU,GAAG,YAAY;AAC7B,YAAMC,SAAS,GAAGC,OAAO,CAACC,GAAR,CAAYC,UAAZ,GAAyB,SAA3C;AACAP,MAAAA,eAAe,CAAC,IAAD,CAAf;AACAQ,MAAAA,OAAO,CAACC,GAAR,CAAY,CACVd,OAAO,CAACe,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0CR,SAA1C,CADU,EAEVT,OAAO,CAACe,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2CR,SAA3C,CAFU,EAGVT,OAAO,CAACe,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4CR,SAA5C,CAHU,EAIVT,OAAO,CAACe,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2CR,SAA3C,CAJU,CAAZ;AAMD,KATD;AAUD,GAXQ,CAAT;AAaA,sBACE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA,4BACE;AAAA,gBAAOL,YAAY,GAAG,cAAH,GAAoB;AAAvC;AAAA;AAAA;AAAA;AAAA,YADF,eAEE;AAAO,MAAA,GAAG,EAAEE,QAAZ;AAAsB,MAAA,EAAE,EAAC,OAAzB;AAAiC,MAAA,QAAQ,MAAzC;AAA0C,MAAA,KAAK,MAA/C;AAAgD,MAAA,MAAM,EAAEJ,WAAxD;AAAqE,MAAA,KAAK,EAAEC;AAA5E;AAAA;AAAA;AAAA;AAAA,YAFF,eAGE;AAAQ,MAAA,GAAG,EAAEI;AAAb;AAAA;AAAA;AAAA;AAAA,YAHF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAOD;;GA5BuBN,G;;KAAAA,G","sourcesContent":["import React, { useEffect, useState, useRef } from 'react';\nimport \"./App.css\";\n\nimport * as faceapi from 'face-api.js';\n\nexport default function App() {\n\n  const videoHeight = 720;\n  const videoWidth = 1280;\n  const [initializing, setInitializing] = useState(false)\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      setInitializing(true);\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)\n      ])\n    }\n  });\n\n  return (\n    <div className=\"main\">\n      <span>{initializing ? \"Initializing\" : \"Ready\"}</span>\n      <video ref={videoRef} id=\"video\" autoplay muted height={videoHeight} width={videoWidth} />\n      <canvas ref={canvasRef} />\n    </div>\n  )\n}\n\n"]},"metadata":{},"sourceType":"module"}