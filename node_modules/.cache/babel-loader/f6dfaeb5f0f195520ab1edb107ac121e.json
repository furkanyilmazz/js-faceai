{"ast":null,"code":"import _regeneratorRuntime from\"/Users/a2017/Documents/GitHub/js-faceai/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";import _asyncToGenerator from\"/Users/a2017/Documents/GitHub/js-faceai/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";import _slicedToArray from\"/Users/a2017/Documents/GitHub/js-faceai/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";import React,{useEffect,useState,useRef}from'react';import\"./App.css\";import*as faceapi from'face-api.js';import{jsx as _jsx}from\"react/jsx-runtime\";import{jsxs as _jsxs}from\"react/jsx-runtime\";export default function App(){var videoHeight=720;var videoWidth=1280;var _useState=useState(false),_useState2=_slicedToArray(_useState,2),initializing=_useState2[0],setInitializing=_useState2[1];var videoRef=useRef();var canvasRef=useRef();useEffect(function(){var loadModels=/*#__PURE__*/function(){var _ref=_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime.mark(function _callee(){var MODEL_URL;return _regeneratorRuntime.wrap(function _callee$(_context){while(1){switch(_context.prev=_context.next){case 0:MODEL_URL=process.env.PUBLIC_URL+'/models';setInitializing(true);Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)]).then(startVideo);case 3:case\"end\":return _context.stop();}}},_callee);}));return function loadModels(){return _ref.apply(this,arguments);};}();loadModels();},[]);var startVideo=function startVideo(){navigator.getUserMedia=navigator.getUserMedia||navigator.webkitGetUserMedia||navigator.mozGetUserMedia;navigator.getUserMedia({video:{}},function(stream){var video=document.querySelector('video');video.srcObject=stream;video.play();},function(err){console.log(\"hata: \"+err.name);});};var handleVideoOnPlay=function handleVideoOnPlay(){setInterval(/*#__PURE__*/_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime.mark(function _callee2(){var displaySize,detections,resizedDetections;return _regeneratorRuntime.wrap(function _callee2$(_context2){while(1){switch(_context2.prev=_context2.next){case 0:if(initializing){setInitializing(false);}canvasRef.current.innerHTML=faceapi.createCanvasFromMedia(videoRef.current);displaySize={width:videoWidth,heigth:videoHeight};faceapi.matchDimensions(canvasRef.current,displaySize);_context2.next=6;return faceapi.detectAllFaces(videoRef.current,new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();case 6:detections=_context2.sent;resizedDetections=faceapi.resizeResults(detections,displaySize);canvasRef.current.getContext('2d').clearRect(0,0,videoWidth,videoHeight);faceapi.draw.drawDetections(canvasRef.current,resizedDetections);faceapi.draw.drawFaceLandmarks(canvasRef.current,resizedDetections);faceapi.draw.drawFaceExpressions(canvasRef.current,resizedDetections);//console.log(detections);\ncase 12:case\"end\":return _context2.stop();}}},_callee2);})),100);};return/*#__PURE__*/_jsxs(\"div\",{className:\"main\",children:[/*#__PURE__*/_jsx(\"span\",{children:initializing?\"Initializing\":\"Ready\"}),/*#__PURE__*/_jsxs(\"div\",{children:[/*#__PURE__*/_jsx(\"video\",{id:\"video\",className:\"video\",ref:videoRef,autoPlay:true,muted:true,height:videoHeight,width:videoWidth,onPlay:handleVideoOnPlay}),/*#__PURE__*/_jsx(\"canvas\",{ref:canvasRef})]})]});}","map":{"version":3,"sources":["/Users/a2017/Documents/GitHub/js-faceai/src/App.js"],"names":["React","useEffect","useState","useRef","faceapi","App","videoHeight","videoWidth","initializing","setInitializing","videoRef","canvasRef","loadModels","MODEL_URL","process","env","PUBLIC_URL","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","startVideo","navigator","getUserMedia","webkitGetUserMedia","mozGetUserMedia","video","stream","document","querySelector","srcObject","play","err","console","log","name","handleVideoOnPlay","setInterval","current","innerHTML","createCanvasFromMedia","displaySize","width","heigth","matchDimensions","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","detections","resizedDetections","resizeResults","getContext","clearRect","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions"],"mappings":"udAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,CAA2BC,QAA3B,CAAqCC,MAArC,KAAmD,OAAnD,CACA,MAAO,WAAP,CAEA,MAAO,GAAKC,CAAAA,OAAZ,KAAyB,aAAzB,C,wFAEA,cAAe,SAASC,CAAAA,GAAT,EAAe,CAE5B,GAAMC,CAAAA,WAAW,CAAG,GAApB,CACA,GAAMC,CAAAA,UAAU,CAAG,IAAnB,CAH4B,cAIYL,QAAQ,CAAC,KAAD,CAJpB,wCAIrBM,YAJqB,eAIPC,eAJO,eAK5B,GAAMC,CAAAA,QAAQ,CAAGP,MAAM,EAAvB,CACA,GAAMQ,CAAAA,SAAS,CAAGR,MAAM,EAAxB,CAEAF,SAAS,CAAC,UAAM,CACd,GAAMW,CAAAA,UAAU,0FAAG,iJACXC,SADW,CACCC,OAAO,CAACC,GAAR,CAAYC,UAAZ,CAAyB,SAD1B,CAEjBP,eAAe,CAAC,IAAD,CAAf,CACAQ,OAAO,CAACC,GAAR,CAAY,CACVd,OAAO,CAACe,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0CR,SAA1C,CADU,CAEVT,OAAO,CAACe,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2CR,SAA3C,CAFU,CAGVT,OAAO,CAACe,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4CR,SAA5C,CAHU,CAIVT,OAAO,CAACe,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2CR,SAA3C,CAJU,CAAZ,EAKGY,IALH,CAKQC,UALR,EAHiB,sDAAH,kBAAVd,CAAAA,UAAU,0CAAhB,CAUAA,UAAU,GACX,CAZQ,CAYN,EAZM,CAAT,CAcA,GAAMc,CAAAA,UAAU,CAAG,QAAbA,CAAAA,UAAa,EAAM,CACvBC,SAAS,CAACC,YAAV,CAAyBD,SAAS,CAACC,YAAV,EACvBD,SAAS,CAACE,kBADa,EAEvBF,SAAS,CAACG,eAFZ,CAIAH,SAAS,CAACC,YAAV,CACE,CACEG,KAAK,CAAE,EADT,CADF,CAIE,SAAUC,MAAV,CAAkB,CAChB,GAAID,CAAAA,KAAK,CAAGE,QAAQ,CAACC,aAAT,CAAuB,OAAvB,CAAZ,CACAH,KAAK,CAACI,SAAN,CAAkBH,MAAlB,CACAD,KAAK,CAACK,IAAN,GACD,CARH,CASE,SAAUC,GAAV,CAAe,CACbC,OAAO,CAACC,GAAR,CAAY,SAAWF,GAAG,CAACG,IAA3B,EACD,CAXH,EAeD,CApBD,CAsBA,GAAMC,CAAAA,iBAAiB,CAAG,QAApBA,CAAAA,iBAAoB,EAAM,CAC9BC,WAAW,sEAAC,qLACV,GAAIlC,YAAJ,CAAkB,CAChBC,eAAe,CAAC,KAAD,CAAf,CACD,CACDE,SAAS,CAACgC,OAAV,CAAkBC,SAAlB,CAA8BxC,OAAO,CAACyC,qBAAR,CAA8BnC,QAAQ,CAACiC,OAAvC,CAA9B,CACMG,WALI,CAKU,CAClBC,KAAK,CAAExC,UADW,CAElByC,MAAM,CAAE1C,WAFU,CALV,CASVF,OAAO,CAAC6C,eAAR,CAAwBtC,SAAS,CAACgC,OAAlC,CAA2CG,WAA3C,EATU,uBAUe1C,CAAAA,OAAO,CAAC8C,cAAR,CAAuBxC,QAAQ,CAACiC,OAAhC,CAAyC,GAAIvC,CAAAA,OAAO,CAAC+C,uBAAZ,EAAzC,EAAgFC,iBAAhF,GAAoGC,mBAApG,EAVf,QAUJC,UAVI,gBAWJC,iBAXI,CAWgBnD,OAAO,CAACoD,aAAR,CAAsBF,UAAtB,CAAkCR,WAAlC,CAXhB,CAYVnC,SAAS,CAACgC,OAAV,CAAkBc,UAAlB,CAA6B,IAA7B,EAAmCC,SAAnC,CAA6C,CAA7C,CAAgD,CAAhD,CAAmDnD,UAAnD,CAA+DD,WAA/D,EACAF,OAAO,CAACuD,IAAR,CAAaC,cAAb,CAA4BjD,SAAS,CAACgC,OAAtC,CAA+CY,iBAA/C,EACAnD,OAAO,CAACuD,IAAR,CAAaE,iBAAb,CAA+BlD,SAAS,CAACgC,OAAzC,CAAkDY,iBAAlD,EACAnD,OAAO,CAACuD,IAAR,CAAaG,mBAAb,CAAiCnD,SAAS,CAACgC,OAA3C,CAAoDY,iBAApD,EACA;AAhBU,yDAAD,GAiBR,GAjBQ,CAAX,CAkBD,CAnBD,CAqBA,mBACE,aAAK,SAAS,CAAC,MAAf,wBACE,sBAAO/C,YAAY,CAAG,cAAH,CAAoB,OAAvC,EADF,cAEE,oCACE,cAAO,EAAE,CAAC,OAAV,CAAkB,SAAS,CAAC,OAA5B,CAAoC,GAAG,CAAEE,QAAzC,CAAmD,QAAQ,KAA3D,CAA4D,KAAK,KAAjE,CAAkE,MAAM,CAAEJ,WAA1E,CAAuF,KAAK,CAAEC,UAA9F,CAA0G,MAAM,CAAEkC,iBAAlH,EADF,cAEE,eAAQ,GAAG,CAAE9B,SAAb,EAFF,GAFF,GADF,CASD","sourcesContent":["import React, { useEffect, useState, useRef } from 'react';\nimport \"./App.css\";\n\nimport * as faceapi from 'face-api.js';\n\nexport default function App() {\n\n  const videoHeight = 720;\n  const videoWidth = 1280;\n  const [initializing, setInitializing] = useState(false)\n  const videoRef = useRef();\n  const canvasRef = useRef();\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      setInitializing(true);\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)\n      ]).then(startVideo)\n    }\n    loadModels();\n  }, []);\n\n  const startVideo = () => {\n    navigator.getUserMedia = navigator.getUserMedia ||\n      navigator.webkitGetUserMedia ||\n      navigator.mozGetUserMedia;\n\n    navigator.getUserMedia(\n      {\n        video: {},\n      },\n      function (stream) {\n        var video = document.querySelector('video');\n        video.srcObject = stream;\n        video.play();\n      },\n      function (err) {\n        console.log(\"hata: \" + err.name);\n      }\n    );\n\n\n  }\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (initializing) {\n        setInitializing(false);\n      }\n      canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(videoRef.current);\n      const displaySize = {\n        width: videoWidth,\n        heigth: videoHeight\n      }\n      faceapi.matchDimensions(canvasRef.current, displaySize);\n      const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n      const resizedDetections = faceapi.resizeResults(detections, displaySize);\n      canvasRef.current.getContext('2d').clearRect(0, 0, videoWidth, videoHeight);\n      faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n      faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n      faceapi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n      //console.log(detections);\n    }, 100)\n  }\n\n  return (\n    <div className=\"main\">\n      <span>{initializing ? \"Initializing\" : \"Ready\"}</span>\n      <div>\n        <video id=\"video\" className=\"video\" ref={videoRef} autoPlay muted height={videoHeight} width={videoWidth} onPlay={handleVideoOnPlay} />\n        <canvas ref={canvasRef} />\n      </div>\n    </div>\n  )\n}\n\n"]},"metadata":{},"sourceType":"module"}